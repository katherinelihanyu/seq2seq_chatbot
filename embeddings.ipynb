{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_embeddings():\n",
    "    \"\"\"\n",
    "    Loads pretrained embeddings from a file and returns\n",
    "    the list of words, a numpy matrix with each row\n",
    "    containing the respective embedding of the word, and a \n",
    "    dictionary with key:value as word:embedding.\n",
    "    \"\"\"\n",
    "    f = open(\"glove.6B.50d.txt\",'r')\n",
    "    vocab = {}\n",
    "    words = []\n",
    "    vectors = []\n",
    "    for line in f:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        embedding = np.array([float(val) for val in tokens[1:]])\n",
    "        words.append(word)\n",
    "        vectors.append(embedding)\n",
    "        vocab[word] = embedding\n",
    "    return words,np.asarray(vectors),vocab\n",
    "\n",
    "WORDS, VECTORS, VOCAB = load_embeddings()\n",
    "\n",
    "train_df = pd.read_csv(\"mini.tsv\", sep=\"\\t\",error_bad_lines=False) #skipped 218 lines\n",
    "# print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.9149e-01,  8.6617e-01,  1.1998e-01,  9.2287e-04,  2.7760e-01,\n",
       "       -4.9185e-01,  5.0195e-01,  6.0792e-04, -2.5845e-01,  1.7865e-01,\n",
       "        2.5350e-01,  7.6572e-01,  5.0664e-01,  4.0250e-01, -2.1388e-03,\n",
       "       -2.8397e-01, -5.0324e-01,  3.0449e-01,  5.1779e-01,  1.5090e-02,\n",
       "       -3.5031e-01, -1.1278e+00,  3.3253e-01, -3.5250e-01,  4.1326e-02,\n",
       "        1.0863e+00,  3.3910e-02,  3.3564e-01,  4.9745e-01, -7.0131e-02,\n",
       "       -1.2192e+00, -4.8512e-01, -3.8512e-02, -1.3554e-01, -1.6380e-01,\n",
       "        5.2321e-01, -3.1318e-01, -1.6550e-01,  1.1909e-01, -1.5115e-01,\n",
       "       -1.5621e-01, -6.2655e-01, -6.2336e-01, -4.2150e-01,  4.1873e-01,\n",
       "       -9.2472e-01,  1.1049e+00, -2.9996e-01, -6.3003e-03,  3.9540e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 71\n",
      "max_index 1062\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index=0\n",
    "for index, row in train_df.iterrows():\n",
    "    if isinstance(row[\"Text\"], str) and len(re.findall(r'^-+|\\w+|\\S+', row[\"Text\"]))>max_len:\n",
    "        # print(row[\"Text\"].split())\n",
    "        # print(re.findall(r'^-+|\\w+|\\S+', row[\"Text\"]))\n",
    "        # print(re.findall(r\"[\\w']+|[.,!?;]\", row[\"Text\"]))\n",
    "        max_len = len(re.findall(r'^-+|\\w+|\\S+', row[\"Text\"]))\n",
    "        max_index = index\n",
    "print(\"max_len\",max_len)\n",
    "print(\"max_index\",max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59214, 50)\n",
      "(59214, 50)\n"
     ]
    }
   ],
   "source": [
    "prev_row=None\n",
    "first = True\n",
    "encoder_input_data_empty = True\n",
    "decoder_input_data_empty = True\n",
    "encoder_input_data = None\n",
    "decoder_input_data = None\n",
    "for index, row in train_df.iterrows():\n",
    "    if not first and isinstance(prev_row[\"Text\"], str) and isinstance(row[\"Text\"], str) and int(prev_row[\"LineID\"][1:]) == int(row[\"LineID\"][1:]) + 1:\n",
    "        vec = np.zeros((max_len,50))\n",
    "        words = re.findall(r'^-+|\\w+|\\S+', prev_row[\"Text\"])\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in VOCAB:\n",
    "                vec[i] = VOCAB[words[i]]\n",
    "            else:\n",
    "                vec[i] = VOCAB['unk']\n",
    "        if encoder_input_data_empty:\n",
    "            encoder_input_data = vec\n",
    "            encoder_input_data_empty = False\n",
    "        else:\n",
    "            encoder_input_data = np.vstack((encoder_input_data,vec))\n",
    "        vec = np.zeros((max_len,50))\n",
    "        words = re.findall(r'^-+|\\w+|\\S+', row[\"Text\"])\n",
    "        for i in range(len(words)):\n",
    "            if words[i] in VOCAB:\n",
    "                vec[i] = VOCAB[words[i]]\n",
    "            else:\n",
    "                vec[i] = VOCAB['unk']\n",
    "        if decoder_input_data_empty:\n",
    "            decoder_input_data = vec\n",
    "            decoder_input_data_empty = False\n",
    "        else:\n",
    "            decoder_input_data = np.vstack((decoder_input_data,vec))\n",
    "    prev_row = row\n",
    "    first = False\n",
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
